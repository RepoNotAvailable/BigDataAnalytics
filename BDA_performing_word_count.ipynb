{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4Jw4P5HgFknQ9Y4lMyvpD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RepoNotAvailable/BigDataAnalytics/blob/main/BDA_performing_word_count.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "#Write a pyspark program to count the no. of words in a txt file from a local system.\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# Configure Spark\n",
        "conf = SparkConf().setAppName(\"WordCount\").setMaster(\"local\")\n",
        "sc = SparkContext(conf=conf)\n",
        "\n",
        "# Install docx2txt if needed\n",
        "!pip install docx2txt\n",
        "\n",
        "# Import docx2txt to extract text from Word document\n",
        "import docx2txt\n",
        "\n",
        "# Extract text from Word file\n",
        "text = docx2txt.process('/content/BDA lec 2.docx')\n",
        "\n",
        "# Create an RDD from the extracted text\n",
        "text_rdd = sc.parallelize([text])\n",
        "\n",
        "# Perform word count\n",
        "word_counts = (\n",
        "    text_rdd\n",
        "    .flatMap(lambda line: line.split())\n",
        "    .map(lambda word: (word, 1))\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        ")\n",
        "\n",
        "\n",
        "for word, count in word_counts.collect():\n",
        "  print(f\"{word}: {count}\")\n",
        "\n",
        "\n",
        "\n",
        "# Stop the Spark context\n",
        "sc.stop()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P52TfD8DiRN",
        "outputId": "121d30fd-1ef9-4337-ca98-566143302062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (0.8)\n",
            "With: 1\n",
            "growing: 1\n",
            "data: 8\n",
            "velocity: 1\n",
            "the: 16\n",
            "size: 1\n",
            "easily: 2\n",
            "outgrows: 1\n",
            "storage: 2\n",
            "limit: 1\n",
            "of: 11\n",
            "a: 6\n",
            "machine.: 1\n",
            "A: 1\n",
            "solution: 1\n",
            "would: 1\n",
            "be: 4\n",
            "to: 3\n",
            "store: 1\n",
            "across: 2\n",
            "network: 3\n",
            "machines.: 1\n",
            "Such: 1\n",
            "filesystems: 1\n",
            "are: 3\n",
            "called: 1\n",
            "distributed: 1\n",
            "filesystems.: 2\n",
            "Since: 1\n",
            "is: 9\n",
            "stored: 2\n",
            "all: 2\n",
            "complications: 1\n",
            "come: 1\n",
            "in.: 2\n",
            "This: 2\n",
            "where: 1\n",
            "Hadoop: 1\n",
            "comes: 1\n",
            "It: 3\n",
            "provides: 2\n",
            "one: 2\n",
            "most: 1\n",
            "reliable: 2\n",
            "HDFS: 5\n",
            "(Hadoop: 1\n",
            "Distributed: 1\n",
            "File: 1\n",
            "System): 1\n",
            "unique: 1\n",
            "design: 1\n",
            "that: 2\n",
            "for: 2\n",
            "extremely: 1\n",
            "large: 3\n",
            "files: 2\n",
            "with: 1\n",
            "streaming: 1\n",
            "access: 1\n",
            "pattern: 1\n",
            "and: 6\n",
            "it: 2\n",
            "runs: 1\n",
            "on: 8\n",
            "commodity: 3\n",
            "hardware.: 3\n",
            "Letâ€™s: 1\n",
            "elaborate: 1\n",
            "terms:: 1\n",
            "Extremely: 1\n",
            "files:: 1\n",
            "Here: 1\n",
            "we: 1\n",
            "talking: 1\n",
            "about: 2\n",
            "in: 4\n",
            "range: 1\n",
            "petabytes(1000: 1\n",
            "TB).: 1\n",
            "Streaming: 1\n",
            "Data: 1\n",
            "Access: 1\n",
            "Pattern:: 1\n",
            "designed: 1\n",
            "principle: 1\n",
            "write-once: 1\n",
            "read-many-times.: 1\n",
            "Once: 1\n",
            "written: 1\n",
            "portions: 1\n",
            "dataset: 1\n",
            "can: 2\n",
            "processed: 1\n",
            "any: 1\n",
            "number: 2\n",
            "times.: 1\n",
            "Commodity: 1\n",
            "hardware:: 1\n",
            "Hardware: 1\n",
            "inexpensive: 1\n",
            "available: 1\n",
            "market.: 1\n",
            "feature: 1\n",
            "which: 2\n",
            "specially: 1\n",
            "distinguishes: 1\n",
            "from: 2\n",
            "other: 1\n",
            "file: 2\n",
            "system.: 1\n",
            "Nodes:: 1\n",
            "Master-slave: 1\n",
            "nodes: 2\n",
            "typically: 1\n",
            "forms: 1\n",
            "cluster.: 1\n",
            "NameNode(MasterNode):: 1\n",
            "Manages: 1\n",
            "slave: 2\n",
            "assign: 1\n",
            "work: 2\n",
            "them.: 1\n",
            "executes: 1\n",
            "filesystem: 1\n",
            "namespace: 1\n",
            "operations: 1\n",
            "like: 3\n",
            "opening,: 1\n",
            "closing,: 1\n",
            "renaming: 1\n",
            "directories.: 1\n",
            "should: 1\n",
            "deployed: 2\n",
            "hardware: 1\n",
            "has: 1\n",
            "high: 3\n",
            "config.: 1\n",
            "not: 1\n",
            "DataNode(SlaveNode):: 1\n",
            "Actual: 1\n",
            "worker: 1\n",
            "nodes,: 1\n",
            "who: 1\n",
            "do: 1\n",
            "actual: 1\n",
            "reading,: 1\n",
            "writing,: 1\n",
            "processing: 1\n",
            "etc.: 2\n",
            "They: 2\n",
            "also: 1\n",
            "perform: 1\n",
            "creation,: 1\n",
            "deletion,: 1\n",
            "replication: 1\n",
            "upon: 1\n",
            "instruction: 1\n",
            "master.: 1\n",
            "daemons:: 1\n",
            "Daemons: 1\n",
            "processes: 1\n",
            "running: 1\n",
            "background.: 1\n",
            "Namenodes:: 1\n",
            "Run: 2\n",
            "master: 1\n",
            "node.: 1\n",
            "Store: 2\n",
            "metadata: 1\n",
            "(data: 1\n",
            "data): 1\n",
            "path,: 1\n",
            "blocks,: 1\n",
            "block: 1\n",
            "Ids.: 1\n",
            "Require: 2\n",
            "amount: 1\n",
            "RAM.: 1\n",
            "meta-data: 1\n",
            "RAM: 1\n",
            "fast: 1\n",
            "retrieval: 1\n",
            "i.e: 1\n",
            "reduce: 1\n",
            "seek: 1\n",
            "time.: 1\n",
            "Though: 1\n",
            "persistent: 1\n",
            "copy: 1\n",
            "kept: 1\n",
            "disk.: 1\n",
            "DataNodes:: 1\n",
            "nodes.: 1\n",
            "memory: 1\n",
            "as: 1\n",
            "actually: 1\n",
            "here.: 1\n"
          ]
        }
      ]
    }
  ]
}